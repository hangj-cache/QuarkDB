## QuarkDB系统问题汇总



super.方法名--他其实是调用了父类对象的方法，针对的是extends的类！！，父类起码要是个类，接口不是类，所以不会是implements



如果long类型的数字在Integer范围内，那么强转为int不会改变数的大小。



一般描述数据大小(size)或者校验和(checksum)---4个字节；描述偏移量(空闲空间偏移量)---2个字节

#### 崩溃的时候要做的就是重做已经提交的事务，然后回滚未提交事务，就是说已提交记录要保留，未提交的操作需要丢弃



#### 一、DB数据恢复问题（MYDB所有内容）

#### 单线程

由于单线程，Ti、Tj 和 Tk 的日志永远不会相交。这种情况下利用日志恢复很简单，假设日志中最后一个事务是 Ti：

1. 对 Ti 之前所有的事务的日志，进行重做（redo）
2. 接着检查 Ti 的状态（XID 文件），如果 Ti 的状态是已完成（包括 committed 和 aborted），就将 Ti 重做，否则进行撤销（undo）

接着，是如何对事务 T 进行 redo：

1. 正序扫描事务 T 的所有日志
2. 如果日志是插入操作 (Ti, I, A, x)，就将 x 重新插入 A 位置
3. 如果日志是更新操作 (Ti, U, A, oldx, newx)，就将 A 位置的值设置为 newx

undo 也很好理解：

1. 倒序扫描事务 T 的所有日志
2. 如果日志是插入操作 (Ti, I, A, x)，就将 A 位置的数据删除
3. 如果日志是更新操作 (Ti, U, A, oldx, newx)，就将 A 位置的值设置为 oldx

注意，MYDB 中其实没有真正的删除操作，对于插入操作的 undo，只是将其中的标志位设置为 invalid。对于删除的探讨将在 VM 一节中进行。

#### 多线程

经过以上的操作，就能保证了 MYDB 在单线程下的恢复性。对于多线程的情况下呢？我们来考虑下面的两种情况。

第一种：

```
T1 begin
T2 begin
T2 U(x)
T1 R(x)
...
T1 commit
MYDB break down
```

在系统崩溃时，T2 仍然是活跃状态。那么当数据库重新启动，执行恢复例程时，会撤销 T2，它对数据库的影响会被消除。但是由于 T1 读取了 T2 更新的值，既然 T2 被撤销，那么 T1 也应当被撤销。这种情况，就是级联回滚。但是，T1 已经 commit 了，所有 commit 的事务的影响，应当被持久化。这里就造成了矛盾。所以这里需要保证：

> 规定 1：正在进行的事务，不会读取其他任何未提交的事务产生的数据。

第二种情况，假设 x 的初值是 0



```
T1 begin
T2 begin
T1 set x = x+1 // 产生的日志为 (T1, U, A, 0, 1)
T2 set x = x+1 // 产生的日志为 (T1, U, A, 1, 2)
T2 commit
MYDB break down
```

在系统崩溃时，T1 仍然是活跃状态。那么当数据库重新启动，执行恢复例程时，会对 T1 进行撤销，对 T2 进行重做，但是，无论撤销和重做的先后顺序如何，x 最后的结果，要么是 0，要么是 2，这都是错误的。

> 出现这种问题的原因，归根结底是因为我们的日志太过简单，仅仅记录了”前相”和”后相”. 并单纯的依靠”前相”undo, 依靠”后相”redo. 这种简单的日志方式和恢复方式，并不能涵盖住所有数据库操作形成的语义

**解决方法有两种：**

1. **增加日志种类**
2. **限制数据库操作**

MYDB 采用的是限制数据库操作，需要保证：

> 规定 2：正在进行的事务，不会修改其他任何未提交的事务修改或产生的数据。

在 MYDB 中，由于 VM 的存在，传递到 DM 层，真正执行的操作序列，都可以保证规定 1 和规定 2。VM 如何保证这两条规定，会在 VM 层一节中说明（VM 的坑还挺大）。有了这两条规定，并发情况下日志的恢复也就很简单了：

1. 重做所有崩溃时已完成（committed 或 aborted）的事务（因为提交不等于写入磁盘，提交等于(redo log)日志写入磁盘）
2. 撤销所有崩溃时未完成（active）的事务

在恢复后，数据库就会恢复到所有已完成事务结束，所有未完成事务尚未开始的状态。

**数据库中的“崩溃”通常指的是**：
 **「内存（缓存）全部丢失，但磁盘上的数据仍然保留」**



**事务提交 ≠ 数据页写入磁盘**
 **事务提交 = 日志（WAL）写入磁盘**

==事务提交和磁盘的真实流程==

我们用 MySQL/InnoDB 为例（大多数数据库也是类似）：

1. **事务执行过程**
   - 修改数据页（存在内存 buffer pool）
   - 生成 redo log（也在内存 log buffer）
2. **提交前**
   - 将 redo log **刷入磁盘（WAL 文件）** ✅
   - 不要求数据页立即写入磁盘 ❌
3. **写成功后，事务返回“提交成功”**
   - 数据页仍可能只在内存中
   - 崩溃后可通过 WAL 重做





==下面针对增加日志种类的方式进行补充==

==增加日志种类==就是比如增加逻辑日志(Logical Logging)

**原理**：

- 不直接记录数据的前后变化，而是记录引起变化的操作本身
- 例如记录`x=x+1`这样的SQL语句或操作指令，而非简单的值变化

**实现方式（就是记录的是操作+操作的值，比如增大，然后增大的值value），详细完整的就是（事务id，操作（增大/减小），变量，值），简单日志的话）（事务id，操作（insert/update），变量，前相，后相）**

```python
# 物理日志（简单日志）
log_entry = (transaction_id, "UPDATE", "x", old_value=0, new_value=1)

# 逻辑日志（增强日志）
log_entry = (transaction_id, "INCREMENT", "x", delta=1)
```

**恢复过程**：

1. 重做已提交事务：重新执行记录的操作
2. 回滚未提交事务：执行逆向操作（如`x=x-1`）

**优点**：

- 能准确保持操作语义
- 适用于所有类型的操作（包括非幂等操作）

**缺点**：

- 日志体积可能增大
- 恢复时需要重新执行操作，可能较慢





#### 二、DB数据存储----实际上插入数据都是插入到页里面（Page），然后最终将页统一刷写到磁盘上

（在 MYDB 这样的数据库系统中，**插入数据的过程就是把数据写入“页（Page）”中，页再统一刷写到磁盘上。**这是数据库**页缓存机制（Buffer Pool）**的核心思想之一。）

**Page 是内存管理的最小单元**

- 在现代操作系统中，**内存（即缓存）是按页（Page）管理的**，常见页大小为 4KB。
- 虚拟内存映射、页表、缺页中断等机制都是以“页”为基本单位。
- 使用 page 做缓存单位，可以直接利用操作系统提供的页缓存、减少管理开销。

> 🧠 举个例子：数据库从磁盘加载数据进内存，也是按页加载，而不是一行一行。

**大多数情况下，数据读写确实是以页为单位的，尤其在以下系统中：**

**✔ 操作系统（文件系统、内存）：**

- **内存读取**：操作系统通过**页表（Page Table）**将虚拟地址映射到物理地址，单位就是页（如4KB）。
- **磁盘读取**：文件系统通常以**块（block）/页**为单位进行磁盘 I/O。即使你只访问一个字节，系统也可能将整页数据载入内存。
- **Page Cache**：操作系统维护的缓存（比如 Linux 的 Page Cache）也是按页组织的。

**✔ 数据库系统：**

- 数据库如 **MySQL（InnoDB）**、**PostgreSQL**：
  - 把数据表存储为一系列“页”（InnoDB默认页大小是16KB）。
  - **查询、插入、更新** 时都以“页”为单位读写磁盘。
  - **Buffer Pool（缓冲池）**管理的也是页，读一条记录就是先加载它所在的页。

因此脏数据其实也成为脏页，所谓脏数据就是值缓存中修改了，但是没有写到磁盘中进行数据同步，又因为数据的读写是以页为单位的，因此脏数据其实就是脏页。



然后锁定的话，可以以页为单位，但是可以细化为行以及表。

#### 总结：

| 问题           | 是否以页为单位         | 说明                                |
| -------------- | ---------------------- | ----------------------------------- |
| **数据读写**   | ✅ 是                   | 文件系统、数据库都是页为基本I/O单元 |
| **加锁操作**   | ✅ 是（可细化到行或表） | 页锁用于索引维护等场景              |
| **脏数据管理** | ✅ 是                   | “脏页”是缓存一致性的核心管理对象    |



适合加锁的情况：

![image-20250621145138622](C:\Users\HangJ\AppData\Roaming\Typora\typora-user-images\image-20250621145138622.png)





#### 三、数据库中的日志类型有很多，其中的日志内容也是不一样的！！！下面是MYDB中的出现的两种日志

1、**物理日志**(又称**数据页日志**)，格式如下：[Size] [Checksum] [Data]，更偏向于**存储层面的数据恢复**。

2、**逻辑日志**或**事务日志（Transaction Log）**，格式如下：updateLog: [LogType] [XID] [OldRaw] [NewRaw]
insertLog: [LogType] [XID] [Pgno] [Raw]，更偏向于**支持事务、回滚和重做**功能。



XID 是事务的 ID，用来标识“一次操作过程”；UID 是记录的唯一 ID，用来标识“一条数据”。



#### 各个数据实体之间区分和辨别

`DataItem` 是数据库中“最小可操作数据单元”；
 它被存储在 `Page` 中，`Page` 被管理在 `PageCache` 里；
 `Logger` 负责记录所有对 `DataItem` 的修改操作，以便崩溃后恢复。

| 模块          | 作用                               | 类似于什么                     |
| ------------- | ---------------------------------- | ------------------------------ |
| **DataItem**  | 一条记录，数据库中最小可操作数据   | 数据行、记录                   |
| **Page**      | 固定大小的块，包含多个 DataItem    | 数据页（比如 8KB）             |
| **PageCache** | 管理磁盘上的 Page 的缓存，提供读写 | 缓冲池（Buffer Pool）          |
| **Logger**    | 记录修改日志（如 update、insert）  | WAL（Write-Ahead Logging）模块 |



| 接口            | 实现类            | 职责说明                                                     |
| --------------- | ----------------- | ------------------------------------------------------------ |
| **DataItem**    | `DataItemImpl`    | 表示单条记录（byte[]），封装锁、脏标记、所属页等元信息       |
| **Page**        | `PageImpl`        | 管理一页内的内容，支持插入、读取、删除 DataItem              |
| **PageCache**   | `PageCacheImpl`   | 管理多个 Page 缓存，控制读写磁盘、缓存页、淘汰页             |
| **Logger**      | `LoggerImpl`      | 负责写入 WAL 日志（update/insert），并支持崩溃恢复           |
| **DataManager** | `DataManagerImpl` | 封装最顶层 API，提供 `read`, `insert`, `update` 等方法，协调上面所有模块 |

| 类名              | 职责描述                                                 |
| ----------------- | -------------------------------------------------------- |
| `DataItemImpl`    | 表示单条记录（包含所属 Page、脏状态、锁等）              |
| `PageImpl`        | 管理单个 Page：分配槽位、插入/删除记录、维护槽位数组     |
| `PageCacheImpl`   | 缓存和磁盘之间的桥梁，支持 Page 加载、刷盘、创建新页     |
| `LoggerImpl`      | 提供日志追加、崩溃恢复、XID 绑定功能                     |
| `DataManagerImpl` | 整体协调器，对外暴露用户操作 API（insert、read、update） |





#### 四、xid

```
xid 在 insert() 中的作用是什么？
long newRootUid = dm.insert(xid, rootRaw);
这里 dm.insert(...) 可能会生成日志、写页缓存、或者调用恢复机制。
传入 xid 让这些组件知道：这个操作属于哪个事务。
如果是 SUPER_XID，意味着：
这是系统操作,不受普通事务的可见性控制,必须立即提交并对所有事务可见
```



`xid`（事务 ID）在数据库系统中就是用来**标识一个事务**的，它的核心作用包括：

**1. 日志记录（Write-Ahead Logging）**

每个事务在对数据库执行修改操作时：

- 都会**生成一条日志记录（redo / undo 日志）**。
- 日志中必须标明：这个操作属于哪个事务 ⇒ `xid`

💡这样在数据库崩溃时可以根据 `xid`：

- 判断哪些事务已经提交 ⇒ 执行 **redo**
- 判断哪些事务未提交 ⇒ 执行 **undo**

**2. 事务隔离与版本控制（MVCC）**

数据库中每条记录通常会附带：

- `xmin`: 插入该数据的事务 ID
- `xmax`: 删除该数据的事务 ID

当前事务的 `xid` 和这些字段配合使用，就能实现：

- 读已提交 / 可重复读 等隔离级别
- 判断这条数据对当前事务是否可见

**3. 恢复（Recovery）**

在数据库重启时：

- 系统会**扫描日志文件**
- 根据 `xid` 判断哪些事务需要恢复提交（redo），哪些需要回滚（undo）

🧱 所以你可以理解为：

> **事务 ID（xid） = 日志的“归属标签” + 版本控制的“时间戳” + 崩溃恢复的关键线索**





#### 五、UID

`uid`（Unique ID）本质上就是该数据在磁盘中的物理地址或者逻辑引用位置。





#### 六、B+树构建---`uid` 就是 **B+树中某个节点在磁盘上的地址**

 `BPlusTree` 类是一个**基于磁盘的数据管理层（DataManager）构建的持久化 B+ 树实现**，其构建流程遵循了数据库系统中 B+ 树的基本设计思路，并通过事务机制（如 `SUPER_XID`）保障操作的原子性与一致性。下面是完整的构建流程总结：

## 🧠 一、核心概念

- **B+树节点存储在磁盘中**，每个节点有唯一的 UID（Unique Identifier）。
- 整棵树通过一个 `bootUid` 启动，即最初记录**根节点 UID**的记录。
- 所有插入、更新、查找操作都以 `bootUid` 为入口，通过递归方式操作磁盘节点。
- 事务号 `SUPER_XID` 用于系统级操作（初始化等）。

------

## 🏗️ 二、构建过程详解

### 🟢 1. 创建 B+ 树（`create(DataManager dm)`）

```java
public static long create(DataManager dm) throws Exception {
    byte[] rawRoot = Node.newNilRootRaw();                   // 创建空的叶子根节点数据--不存数据
    long rootUid = dm.insert(SUPER_XID, rawRoot);            // 插入根节点，获取其 UID
    return dm.insert(SUPER_XID, Parser.long2Byte(rootUid));  // 用 rootUid 创建“boot record”，并返回其 UID（bootUid）
}
```

- 创建一个**空的根节点**（作为叶子节点）。
- 将其插入磁盘，返回 `rootUid`。
- 将 `rootUid` 转换为 8 字节数据存入新的记录（即 `bootDataItem`）。
- 返回此“引导记录”的 UID，作为整棵树的入口。

------

### 🟡 2. 加载 B+ 树（`load(long bootUid, DataManager dm)`）

```java
public static BPlusTree load(long bootUid, DataManager dm)
```

- 加载之前创建的 `bootUid` 对应的记录（bootDataItem）。
- 从中解析出当前根节点的 UID（8 字节存储）。
- 初始化 `BPlusTree` 实例，并保持 bootDataItem 的引用。

```
@Override  // 根据uid读取对应的数据,这个uid可以是getting中的key，也可以是cache中的key，也可以是也缓存中的页码，用于此磁盘中读取对应数据
public DataItem read(long uid) throws Exception {
    DataItemImpl di = (DataItemImpl) super.get(uid);
    if(!di.isValid()){
        di.release();
        return null;
    }
    return di;
}
```

------

## 🌳 三、插入过程（核心构建逻辑）

### 🔁 insert(long key, long uid)   uid表示地址

这是插入一个 `(key, dataUid)` 的入口：

1. 调用 `rootUid()` 获取当前根节点。
2. 调用递归插入逻辑 `insert(...)`。
3. 如果插入导致根节点分裂，则调用 `updateRootUid(...)` 创建新的根节点。

------

### 🔄 insert(...) 递归插入

```java
private InsertRes insert(long nodeUid, long uid, long key)
```

- 如果是叶子节点 → 执行 `insertAndSplit(...)`。
- 如果是中间节点 → 找到对应子节点，递归插入；如果子节点分裂，需要将中间键插入当前节点。

------

### ✂️ insertAndSplit(...)

```java
Node.InsertAndSplitRes iasr = node.insertAndSplit(uid, key)
```

- 执行节点内部插入。
- 如果节点溢出 → 分裂并返回：
  - `newSon`: 新分裂出来的节点的 UID。
  - `newKey`: 分裂时的中间键（推向上层节点）。

------

### ⬆️ updateRootUid(...)

如果原根节点发生了分裂：

1. 创建一个**新的非叶子根节点**，包含左右孩子。
2. 把新的根节点写入磁盘，获取 `newRootUid`。
3. 使用 `bootLock` 加锁，更新 bootDataItem 里的 rootUid。
4. 用 `SUPER_XID` 提交修改。

------

## 🔍 四、查询逻辑（search & searchRange）

### search(key)

- 调用 `searchRange(key, key)` 进行单键查询。

### searchRange(leftKey, rightKey)

1. 从 `rootUid()` 开始递归，找到包含 `leftKey` 的叶子节点。
2. 逐个遍历叶子节点链表（通过 siblingUid 链接），收集范围内的 key。
3. 返回所有匹配的记录 UID。

------

## 🧱 五、辅助类说明

- `Node`：封装了节点的结构与插入、查找、分裂等操作。
- `bootDataItem`：表示存储根节点 UID 的特殊记录，是整个 B+ 树的入口。
- `InsertRes`：用于记录插入过程中产生的新节点和中间 key。

------

## ✅ 总结

> 这个 `BPlusTree` 是一个**磁盘持久化、支持事务、支持范围查找与分裂重构的 B+ 树实现**，非常适合用于数据库索引系统中。

**构建核心步骤：**

1. `create()` 创建根节点并保存为 bootUid。
2. `insert(key, uid)` 递归插入，必要时自动分裂并构造新的根。
3. 所有查找以 bootUid 为起点递归执行，支持范围查找。
4. 所有磁盘修改通过 `DataManager` + `TransactionManager` 执行，保证持久性与一致性。

![ChatGPT Image 2025年7月6日 17_36_21](C:\Users\HangJ\Downloads\ChatGPT Image 2025年7月6日 17_36_21.png)